{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "from collections import Counter\n",
    "import math\n",
    "from math import exp\n",
    "from scipy.spatial.distance import cdist\n",
    "import scipy\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "from itertools import combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iris.data #iris is a dictionary and hence we re gettiing data by keys.\n",
    "labels = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KM_plusplus():\n",
    "    '''This class uses KMeans++ algorithm for initial centroid location which are not random. This imporves the cluster\n",
    "    quality and gives persistent clustering.\n",
    "    \n",
    "    Parameters\n",
    "    ----------------\n",
    "    n_clusters: int\n",
    "        number of clusters to find. They are group of datapoints that will form clusters based of the distance from \n",
    "        centroid.\n",
    "    \n",
    "    Attributes\n",
    "    ----------------\n",
    "    centroids_: array, shape (n_clusters, xtrain.shape[1])\n",
    "        centroid, center point of cluster from where distance of cluster points is minimum. \n",
    "        \n",
    "    classes_: dict, should have same number of datapoints as the original dataset.\n",
    "        group of datapoints forming the clusters.\n",
    "    '''\n",
    "    def __init__(self, n_clusters):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.centroids_ = 0 \n",
    "        self.classes_ = 0\n",
    "        \n",
    "    def fit(self, xtrain, method='km++'):\n",
    "        '''fit method implements Lloyd's algorithm, whenever the centroids (center of mass of cluster) stop moving, \n",
    "        stop iteration. Euclidean pairwise distance between each datapoint and every centroid is measured and datapoint\n",
    "        is allocated to nearest centroid\n",
    "        \n",
    "        Parameters\n",
    "        ----------------\n",
    "        xtrain: pd.dataframe\n",
    "            \n",
    "        method: str (default 'km++') {'km++', 'random'}\n",
    "            specify which algorithm to use for calculating initial centroids. \n",
    "        '''\n",
    "        \n",
    "        if method=='km++':\n",
    "            self.centroids_ = self.centroid_initialize(xtrain, self.n_clusters)\n",
    "        elif method=='random':\n",
    "            self.centroids_= xtrain.sample(self.n_clusters).values #random initialization of clusters\n",
    "        else:\n",
    "            print('This method is not implemented')\n",
    "            \n",
    "        previous = np.zeros(self.centroids_.shape)\n",
    "        error = np.linalg.norm(self.centroids_ - previous) #initialize error for iteration\n",
    "        #print(error)\n",
    "        count = 0\n",
    "        while error >= 0.005:\n",
    "        #implementing Lloyd algorithms(stop when new cluster does not move)\n",
    "            count += 1\n",
    "            self.classes_ = {}\n",
    "            for index in range(self.n_clusters):\n",
    "                self.classes_[index] = []\n",
    "            for row in xtrain.values:\n",
    "                    #distances = [np.linalg.norm(row - centroid) for centroid in centroids.values]\n",
    "                    distances = [np.linalg.norm(row - centroid) for centroid in self.centroids_]\n",
    "                    classify = distances.index(min(distances))\n",
    "                    self.classes_[classify].append(row)\n",
    "            previous = deepcopy(self.centroids_)\n",
    "            for classify in self.classes_:\n",
    "                #print(classify, classes[classify])\n",
    "                #print(np.mean(classes[classify], axis =0))\n",
    "                self.centroids_[classify] = np.mean(self.classes_[classify], axis=0)\n",
    "            #print(previous)\n",
    "            #print(centroids)\n",
    "\n",
    "            error = np.linalg.norm(previous-self.centroids_)\n",
    "            print(error)\n",
    "        #print(self.classes_)\n",
    "        print(count) #printing number of iteration for reaching minimum error\n",
    "        return self.centroids_ \n",
    "    \n",
    "    def centroid_initialize(self, xtrain, random_seed=None):\n",
    "        '''k-means++ algorithm, searching for farthest point (.85 of farthest point, as farthest point can be outliers) \n",
    "        for next centroid, vectorized'''\n",
    "    \n",
    "        centroid = xtrain.sample(1).values # add a random seed    \n",
    "        centroids = {}\n",
    "        for i in range(1,self.n_clusters):\n",
    "            for index, item in enumerate(centroid):\n",
    "                item = item.reshape(-1, item.shape[0])\n",
    "                euclidean_dist = cdist(xtrain.values, item)\n",
    "                centroids[index] = euclidean_dist\n",
    "            minim = []\n",
    "            for i in zip(*centroids.values()):\n",
    "                minim.append(min(i))\n",
    "            r = 0.85*float(max(minim))\n",
    "\n",
    "            index = np.where(np.array(minim) >= r)[0][0]\n",
    "            centroid = np.vstack((centroid, xtrain.iloc[index].values))\n",
    "        return centroid\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.738659977595\n",
      "0.370141728842\n",
      "0.112262087317\n",
      "0.0874869355307\n",
      "0.0\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 5.9016129 ,  2.7483871 ,  4.39354839,  1.43387097],\n",
       "       [ 5.006     ,  3.418     ,  1.464     ,  0.244     ],\n",
       "       [ 6.85      ,  3.07368421,  5.74210526,  2.07105263]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km  = KM_plusplus(3)\n",
    "km.fit(iris_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.9016129 ,  2.7483871 ,  4.39354839,  1.43387097],\n",
       "       [ 5.006     ,  3.418     ,  1.464     ,  0.244     ],\n",
       "       [ 6.85      ,  3.07368421,  5.74210526,  2.07105263]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.centroids_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [array([ 7. ,  3.2,  4.7,  1.4]),\n",
       "  array([ 6.4,  3.2,  4.5,  1.5]),\n",
       "  array([ 5.5,  2.3,  4. ,  1.3]),\n",
       "  array([ 6.5,  2.8,  4.6,  1.5]),\n",
       "  array([ 5.7,  2.8,  4.5,  1.3]),\n",
       "  array([ 6.3,  3.3,  4.7,  1.6]),\n",
       "  array([ 4.9,  2.4,  3.3,  1. ]),\n",
       "  array([ 6.6,  2.9,  4.6,  1.3]),\n",
       "  array([ 5.2,  2.7,  3.9,  1.4]),\n",
       "  array([ 5. ,  2. ,  3.5,  1. ]),\n",
       "  array([ 5.9,  3. ,  4.2,  1.5]),\n",
       "  array([ 6. ,  2.2,  4. ,  1. ]),\n",
       "  array([ 6.1,  2.9,  4.7,  1.4]),\n",
       "  array([ 5.6,  2.9,  3.6,  1.3]),\n",
       "  array([ 6.7,  3.1,  4.4,  1.4]),\n",
       "  array([ 5.6,  3. ,  4.5,  1.5]),\n",
       "  array([ 5.8,  2.7,  4.1,  1. ]),\n",
       "  array([ 6.2,  2.2,  4.5,  1.5]),\n",
       "  array([ 5.6,  2.5,  3.9,  1.1]),\n",
       "  array([ 5.9,  3.2,  4.8,  1.8]),\n",
       "  array([ 6.1,  2.8,  4. ,  1.3]),\n",
       "  array([ 6.3,  2.5,  4.9,  1.5]),\n",
       "  array([ 6.1,  2.8,  4.7,  1.2]),\n",
       "  array([ 6.4,  2.9,  4.3,  1.3]),\n",
       "  array([ 6.6,  3. ,  4.4,  1.4]),\n",
       "  array([ 6.8,  2.8,  4.8,  1.4]),\n",
       "  array([ 6. ,  2.9,  4.5,  1.5]),\n",
       "  array([ 5.7,  2.6,  3.5,  1. ]),\n",
       "  array([ 5.5,  2.4,  3.8,  1.1]),\n",
       "  array([ 5.5,  2.4,  3.7,  1. ]),\n",
       "  array([ 5.8,  2.7,  3.9,  1.2]),\n",
       "  array([ 6. ,  2.7,  5.1,  1.6]),\n",
       "  array([ 5.4,  3. ,  4.5,  1.5]),\n",
       "  array([ 6. ,  3.4,  4.5,  1.6]),\n",
       "  array([ 6.7,  3.1,  4.7,  1.5]),\n",
       "  array([ 6.3,  2.3,  4.4,  1.3]),\n",
       "  array([ 5.6,  3. ,  4.1,  1.3]),\n",
       "  array([ 5.5,  2.5,  4. ,  1.3]),\n",
       "  array([ 5.5,  2.6,  4.4,  1.2]),\n",
       "  array([ 6.1,  3. ,  4.6,  1.4]),\n",
       "  array([ 5.8,  2.6,  4. ,  1.2]),\n",
       "  array([ 5. ,  2.3,  3.3,  1. ]),\n",
       "  array([ 5.6,  2.7,  4.2,  1.3]),\n",
       "  array([ 5.7,  3. ,  4.2,  1.2]),\n",
       "  array([ 5.7,  2.9,  4.2,  1.3]),\n",
       "  array([ 6.2,  2.9,  4.3,  1.3]),\n",
       "  array([ 5.1,  2.5,  3. ,  1.1]),\n",
       "  array([ 5.7,  2.8,  4.1,  1.3]),\n",
       "  array([ 5.8,  2.7,  5.1,  1.9]),\n",
       "  array([ 4.9,  2.5,  4.5,  1.7]),\n",
       "  array([ 5.7,  2.5,  5. ,  2. ]),\n",
       "  array([ 5.8,  2.8,  5.1,  2.4]),\n",
       "  array([ 6. ,  2.2,  5. ,  1.5]),\n",
       "  array([ 5.6,  2.8,  4.9,  2. ]),\n",
       "  array([ 6.3,  2.7,  4.9,  1.8]),\n",
       "  array([ 6.2,  2.8,  4.8,  1.8]),\n",
       "  array([ 6.1,  3. ,  4.9,  1.8]),\n",
       "  array([ 6.3,  2.8,  5.1,  1.5]),\n",
       "  array([ 6. ,  3. ,  4.8,  1.8]),\n",
       "  array([ 5.8,  2.7,  5.1,  1.9]),\n",
       "  array([ 6.3,  2.5,  5. ,  1.9]),\n",
       "  array([ 5.9,  3. ,  5.1,  1.8])],\n",
       " 1: [array([ 5.1,  3.5,  1.4,  0.2]),\n",
       "  array([ 4.9,  3. ,  1.4,  0.2]),\n",
       "  array([ 4.7,  3.2,  1.3,  0.2]),\n",
       "  array([ 4.6,  3.1,  1.5,  0.2]),\n",
       "  array([ 5. ,  3.6,  1.4,  0.2]),\n",
       "  array([ 5.4,  3.9,  1.7,  0.4]),\n",
       "  array([ 4.6,  3.4,  1.4,  0.3]),\n",
       "  array([ 5. ,  3.4,  1.5,  0.2]),\n",
       "  array([ 4.4,  2.9,  1.4,  0.2]),\n",
       "  array([ 4.9,  3.1,  1.5,  0.1]),\n",
       "  array([ 5.4,  3.7,  1.5,  0.2]),\n",
       "  array([ 4.8,  3.4,  1.6,  0.2]),\n",
       "  array([ 4.8,  3. ,  1.4,  0.1]),\n",
       "  array([ 4.3,  3. ,  1.1,  0.1]),\n",
       "  array([ 5.8,  4. ,  1.2,  0.2]),\n",
       "  array([ 5.7,  4.4,  1.5,  0.4]),\n",
       "  array([ 5.4,  3.9,  1.3,  0.4]),\n",
       "  array([ 5.1,  3.5,  1.4,  0.3]),\n",
       "  array([ 5.7,  3.8,  1.7,  0.3]),\n",
       "  array([ 5.1,  3.8,  1.5,  0.3]),\n",
       "  array([ 5.4,  3.4,  1.7,  0.2]),\n",
       "  array([ 5.1,  3.7,  1.5,  0.4]),\n",
       "  array([ 4.6,  3.6,  1. ,  0.2]),\n",
       "  array([ 5.1,  3.3,  1.7,  0.5]),\n",
       "  array([ 4.8,  3.4,  1.9,  0.2]),\n",
       "  array([ 5. ,  3. ,  1.6,  0.2]),\n",
       "  array([ 5. ,  3.4,  1.6,  0.4]),\n",
       "  array([ 5.2,  3.5,  1.5,  0.2]),\n",
       "  array([ 5.2,  3.4,  1.4,  0.2]),\n",
       "  array([ 4.7,  3.2,  1.6,  0.2]),\n",
       "  array([ 4.8,  3.1,  1.6,  0.2]),\n",
       "  array([ 5.4,  3.4,  1.5,  0.4]),\n",
       "  array([ 5.2,  4.1,  1.5,  0.1]),\n",
       "  array([ 5.5,  4.2,  1.4,  0.2]),\n",
       "  array([ 4.9,  3.1,  1.5,  0.1]),\n",
       "  array([ 5. ,  3.2,  1.2,  0.2]),\n",
       "  array([ 5.5,  3.5,  1.3,  0.2]),\n",
       "  array([ 4.9,  3.1,  1.5,  0.1]),\n",
       "  array([ 4.4,  3. ,  1.3,  0.2]),\n",
       "  array([ 5.1,  3.4,  1.5,  0.2]),\n",
       "  array([ 5. ,  3.5,  1.3,  0.3]),\n",
       "  array([ 4.5,  2.3,  1.3,  0.3]),\n",
       "  array([ 4.4,  3.2,  1.3,  0.2]),\n",
       "  array([ 5. ,  3.5,  1.6,  0.6]),\n",
       "  array([ 5.1,  3.8,  1.9,  0.4]),\n",
       "  array([ 4.8,  3. ,  1.4,  0.3]),\n",
       "  array([ 5.1,  3.8,  1.6,  0.2]),\n",
       "  array([ 4.6,  3.2,  1.4,  0.2]),\n",
       "  array([ 5.3,  3.7,  1.5,  0.2]),\n",
       "  array([ 5. ,  3.3,  1.4,  0.2])],\n",
       " 2: [array([ 6.9,  3.1,  4.9,  1.5]),\n",
       "  array([ 6.7,  3. ,  5. ,  1.7]),\n",
       "  array([ 6.3,  3.3,  6. ,  2.5]),\n",
       "  array([ 7.1,  3. ,  5.9,  2.1]),\n",
       "  array([ 6.3,  2.9,  5.6,  1.8]),\n",
       "  array([ 6.5,  3. ,  5.8,  2.2]),\n",
       "  array([ 7.6,  3. ,  6.6,  2.1]),\n",
       "  array([ 7.3,  2.9,  6.3,  1.8]),\n",
       "  array([ 6.7,  2.5,  5.8,  1.8]),\n",
       "  array([ 7.2,  3.6,  6.1,  2.5]),\n",
       "  array([ 6.5,  3.2,  5.1,  2. ]),\n",
       "  array([ 6.4,  2.7,  5.3,  1.9]),\n",
       "  array([ 6.8,  3. ,  5.5,  2.1]),\n",
       "  array([ 6.4,  3.2,  5.3,  2.3]),\n",
       "  array([ 6.5,  3. ,  5.5,  1.8]),\n",
       "  array([ 7.7,  3.8,  6.7,  2.2]),\n",
       "  array([ 7.7,  2.6,  6.9,  2.3]),\n",
       "  array([ 6.9,  3.2,  5.7,  2.3]),\n",
       "  array([ 7.7,  2.8,  6.7,  2. ]),\n",
       "  array([ 6.7,  3.3,  5.7,  2.1]),\n",
       "  array([ 7.2,  3.2,  6. ,  1.8]),\n",
       "  array([ 6.4,  2.8,  5.6,  2.1]),\n",
       "  array([ 7.2,  3. ,  5.8,  1.6]),\n",
       "  array([ 7.4,  2.8,  6.1,  1.9]),\n",
       "  array([ 7.9,  3.8,  6.4,  2. ]),\n",
       "  array([ 6.4,  2.8,  5.6,  2.2]),\n",
       "  array([ 6.1,  2.6,  5.6,  1.4]),\n",
       "  array([ 7.7,  3. ,  6.1,  2.3]),\n",
       "  array([ 6.3,  3.4,  5.6,  2.4]),\n",
       "  array([ 6.4,  3.1,  5.5,  1.8]),\n",
       "  array([ 6.9,  3.1,  5.4,  2.1]),\n",
       "  array([ 6.7,  3.1,  5.6,  2.4]),\n",
       "  array([ 6.9,  3.1,  5.1,  2.3]),\n",
       "  array([ 6.8,  3.2,  5.9,  2.3]),\n",
       "  array([ 6.7,  3.3,  5.7,  2.5]),\n",
       "  array([ 6.7,  3. ,  5.2,  2.3]),\n",
       "  array([ 6.5,  3. ,  5.2,  2. ]),\n",
       "  array([ 6.2,  3.4,  5.4,  2.3])]}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I wrote multiple vectorized implementation for finding initial centroids. Using scipy.cdist, np.inner and pairwise.euclidean_distance methods. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid_initialize(xtrain, n_centroid):\n",
    "## k-means++ approach, searching for farthest point for next centroid with probability function, tweeked to avoid getting outliers\n",
    "    centroid = xtrain.sample(1).as_matrix()\n",
    "    \n",
    "    for i in range(1,n_centroid):\n",
    "        #print(centroid)\n",
    "        dist = np.array([min([np.inner(c-x,c-x)for c in centroid]) for x in xtrain.values])\n",
    "        #print(dist)\n",
    "        dist_prob = dist/dist.sum()\n",
    "        cum_dist = dist_prob.cumsum()\n",
    "        index = np.where(cum_dist >= 0.85)[0][0]\n",
    "        #print(index)\n",
    "        centroid = np.vstack((centroid, xtrain.iloc[index].values))\n",
    "    return centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid_initialize2(xtrain, n_centroid, random_seed=None):\n",
    "## k-means++ approach, searching for farthest point for next centroid with probability function, vectorized\n",
    "    centroid = xtrain.sample(1).values # .values add a random seed    \n",
    "    centroids = {}\n",
    "    for i in range(1,n_centroid):\n",
    "        for index, item in enumerate(centroid):\n",
    "            item = item.reshape(-1, item.shape[0])\n",
    "            euclidean_dist = cdist(xtrain.values, item)\n",
    "            centroids[index] = euclidean_dist\n",
    "        minim = []\n",
    "        for i in zip(*centroids.values()):\n",
    "            minim.append(min(i))\n",
    "        r = 0.85*float(max(minim))\n",
    "\n",
    "        index = np.where(np.array(minim) >= r)[0][0]\n",
    "        centroid = np.vstack((centroid, xtrain.iloc[index].values))\n",
    "    return centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "def centroid_initialize3(xtrain, n_centroid, random_seed=None):\n",
    "    centroids = xtrain.sample(1).values.reshape( (1,) + xtrain.shape[1:])\n",
    "    \n",
    "    for i in range(n_centroid-1): \n",
    "        d_x = np.min(euclidean_distances(xtrain, centroids), axis=1)\n",
    "        d_x = d_x / np.sum(d_x)\n",
    "        new_centroid = xtrain.iloc[np.random.choice(len(xtrain), size=1, p=d_x)]\n",
    "        centroids = np.vstack((centroids, new_centroid))\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid_initialize1(xtrain, n_centroid):\n",
    "## k-means++ approach, searching for farthest point for next centroid with probability function\n",
    "    centroid = xtrain.sample(1)\n",
    "    print(centroid.values)\n",
    "    \n",
    "    centroids = {}\n",
    "    #for i in range(1,n_centroid):\n",
    "    for index, item in enumerate(centroid.values):\n",
    "        item = item.reshape(-1, item.shape[0])\n",
    "            #print(np.linalg.norm(xtrain.values[1] - item)\n",
    "        euclidean_dist = cdist(xtrain.values, item)\n",
    "        centroids[index] = euclidean_dist\n",
    "\n",
    "        #print(centroids)\n",
    "    minim = []\n",
    "        #print(list(zip(*centroids.values())))\n",
    "    for i in zip(*centroids.values()):\n",
    "        minim.append(min(i))\n",
    "    r = 0.85*float(max(minim))\n",
    "\n",
    "    index = np.where(np.array(minim) >= r)[0][0]\n",
    "    centroid = np.vstack((centroid, xtrain.iloc[index].values))\n",
    "    print(r,(minim), index)\n",
    "    return centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.7,  3.3,  5.7,  2.1],\n",
       "       [ 5.2,  2.7,  3.9,  1.4]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroid_initialize(iris_df, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn KMeans clustering comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=3, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km = KMeans(n_clusters=3)\n",
    "km.fit(iris_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.9016129 ,  2.7483871 ,  4.39354839,  1.43387097],\n",
       "       [ 5.006     ,  3.418     ,  1.464     ,  0.244     ],\n",
       "       [ 6.85      ,  3.07368421,  5.74210526,  2.07105263]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method KMeans.predict of KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=3, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
